{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19fa85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b431a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman/miniforge3/envs/scaleflow/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scaleflow.data import AnnDataLocation, DataManager, GroupedDistribution, prepare_datasets, split_datasets\n",
    "from scaleflow.data._dataloader import CombinedSampler, InMemorySampler, ReservoirSampler\n",
    "from scaleflow.datasets import sample_adata\n",
    "from scaleflow.model import ScaleFlow\n",
    "from scaleflow.training import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdd0c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman/miniforge3/envs/scaleflow/lib/python3.12/functools.py:912: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/Users/selman/miniforge3/envs/scaleflow/lib/python3.12/functools.py:912: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/Users/selman/miniforge3/envs/scaleflow/lib/python3.12/functools.py:912: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    }
   ],
   "source": [
    "adata1, adata2, adata3 = sample_adata(), sample_adata(), sample_adata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d86aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "adl = AnnDataLocation()\n",
    "data_manager = DataManager(\n",
    "    dist_flag_key=\"control\",\n",
    "    src_dist_keys=[\"cell_line\"],\n",
    "    tgt_dist_keys=[\"drug\", \"gene\"],\n",
    "    rep_keys={\n",
    "        \"cell_line\": \"cell_line_embeddings\",\n",
    "        \"drug\": \"drug_embeddings\",\n",
    "        \"gene\": \"gene_embeddings\",\n",
    "    },\n",
    "    data_location=adl.obsm[\"X_pca\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af54802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing /data/src_data: 100%|██████████| 2/2 [00:00<00:00, 346.91it/s]\n",
      "Writing /data/tgt_data: 100%|██████████| 16/16 [00:00<00:00, 475.97it/s]\n",
      "Writing /data/conditions: 100%|██████████| 3/3 [00:00<00:00, 228.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing annotation\n"
     ]
    }
   ],
   "source": [
    "gd1_mem = data_manager.prepare_data(adata1)\n",
    "gd1_mem.write_zarr(\"data/gd1.zarr\")\n",
    "gd1 = GroupedDistribution.read_zarr(\"data/gd1.zarr\")\n",
    "del gd1_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973f0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd2 = data_manager.prepare_data(adata2)\n",
    "gd3 = data_manager.prepare_data(adata3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855826be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_datasets({\"gd1\": gd1, \"gd2\": gd2, \"gd3\": gd3}, split_by=[\"drug\"], split_key=\"split\", ratios=[0.4, 0.3, 0.3], random_state=42, holdout_combinations=False)\n",
    "train_splits = {k:v[\"train\"] for k,v in data.items()}\n",
    "val_splits = {k:v[\"val\"] for k,v in data.items()}\n",
    "ds1, ds2, ds3 = train_splits[\"gd1\"], train_splits[\"gd2\"], train_splits[\"gd3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be96ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler =CombinedSampler(\n",
    "    samplers={\n",
    "        \"gd1\": ReservoirSampler(\n",
    "            gd1, np.random.default_rng(42), batch_size=1024, pool_fraction=0.5, replacement_prob=0.1\n",
    "        ),\n",
    "        \"gd2\": InMemorySampler(gd2, np.random.default_rng(43), batch_size=1024),\n",
    "        \"gd3\": InMemorySampler(gd3, np.random.default_rng(44), batch_size=1024),\n",
    "    },\n",
    "    rng=np.random.default_rng(42),\n",
    ")\n",
    "val_sampler =CombinedSampler(\n",
    "    samplers={\n",
    "        \"gd1\": ReservoirSampler(\n",
    "            val_splits[\"gd1\"], np.random.default_rng(42), batch_size=1024, pool_fraction=0.5, replacement_prob=0.1\n",
    "        ),\n",
    "        \"gd2\": InMemorySampler(val_splits[\"gd2\"], np.random.default_rng(43), batch_size=1024),\n",
    "        \"gd3\": InMemorySampler(val_splits[\"gd3\"], np.random.default_rng(44), batch_size=1024),\n",
    "    },\n",
    "    rng=np.random.default_rng(42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ace771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.init_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "543a5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch =sampler.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4540b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = ScaleFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1017f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.prepare_model(\n",
    "    sample_batch=sample_batch,\n",
    "    max_combination_length=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db8bc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x must be at least two-dimensional for matrix_transpose; got ndim=1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/model/_scaleflow.py:673\u001b[39m, in \u001b[36mScaleFlow.train\u001b[39m\u001b[34m(self, num_iterations, batch_size, valid_freq, validation_batch_size, callbacks, monitor_metrics, train_dataloader, val_dataloader, out_of_core_dataloading, num_workers, prefetch_factor)\u001b[39m\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mModel not initialized. Please call `prepare_model` first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# validation_dataloaders = {}\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m# for k, v in self._validation_data.items():\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;66;03m#     if k != \"predict_kwargs\":\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m#         val_sampler = InMemorySampler()\u001b[39;00m\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m#         validation_dataloaders[k] = val_sampler\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m \u001b[38;5;28mself\u001b[39m._solver = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_loaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmonitor_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmonitor_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/training/_trainer.py:147\u001b[39m, in \u001b[36mCellFlowTrainer.train\u001b[39m\u001b[34m(self, dataloader, num_iterations, valid_freq, valid_loaders, monitor_metrics, callbacks)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# Sample batch (dataloader controls which task)\u001b[39;00m\n\u001b[32m    146\u001b[39m batch = sampler.sample()\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_step_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Track losses\u001b[39;00m\n\u001b[32m    150\u001b[39m task = batch.get(\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/solvers/_otfm.py:215\u001b[39m, in \u001b[36mOTFlowMatching.step_fn\u001b[39m\u001b[34m(self, rng, batch)\u001b[39m\n\u001b[32m    212\u001b[39m task = batch.get(\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgex\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task == \u001b[33m\"\u001b[39m\u001b[33mgex\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_gex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task == \u001b[33m\"\u001b[39m\u001b[33mfunctional\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._step_functional(rng, batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/solvers/_otfm.py:235\u001b[39m, in \u001b[36mOTFlowMatching._step_gex\u001b[39m\u001b[34m(self, rng, batch)\u001b[39m\n\u001b[32m    232\u001b[39m     src_ixs, tgt_ixs = solver_utils.sample_joint(rng_resample, tmat)\n\u001b[32m    233\u001b[39m     src, tgt = src[src_ixs], tgt[tgt_ixs]\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28mself\u001b[39m.vf_state, loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf_step_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrng_step_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ema == \u001b[32m1.0\u001b[39m:\n\u001b[32m    246\u001b[39m     \u001b[38;5;28mself\u001b[39m.vf_state_inference = \u001b[38;5;28mself\u001b[39m.vf_state\n",
      "    \u001b[31m[... skipping hidden 13 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/solvers/_otfm.py:127\u001b[39m, in \u001b[36mOTFlowMatching._get_vf_step_fn.<locals>.vf_step_fn\u001b[39m\u001b[34m(rng, vf_state, time, source, target, conditions, encoder_noise)\u001b[39m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m flow_matching_loss + encoder_loss\n\u001b[32m    126\u001b[39m grad_fn = jax.value_and_grad(loss_fn)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m loss, grads = \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvf_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vf_state.apply_gradients(grads=grads), loss\n",
      "    \u001b[31m[... skipping hidden 10 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/solvers/_otfm.py:106\u001b[39m, in \u001b[36mOTFlowMatching._get_vf_step_fn.<locals>.vf_step_fn.<locals>.loss_fn\u001b[39m\u001b[34m(params, t, source, target, conditions, encoder_noise, rng)\u001b[39m\n\u001b[32m    104\u001b[39m rng_flow, rng_encoder, rng_dropout = jax.random.split(rng, \u001b[32m3\u001b[39m)\n\u001b[32m    105\u001b[39m x_t = \u001b[38;5;28mself\u001b[39m.probability_path.compute_xt(rng_flow, t, source, target)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m v_t, mean_cond, logvar_cond = \u001b[43mvf_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_noise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrngs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_dropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcondition_encoder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_encoder\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m u_t = \u001b[38;5;28mself\u001b[39m.probability_path.compute_ut(t, x_t, source, target)\n\u001b[32m    115\u001b[39m flow_matching_loss = jnp.mean((v_t - u_t) ** \u001b[32m2\u001b[39m)\n",
      "    \u001b[31m[... skipping hidden 6 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/networks/_velocity_field.py:238\u001b[39m, in \u001b[36mConditionalVelocityField.__call__\u001b[39m\u001b[34m(self, t, x_t, cond, encoder_noise, train)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    230\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    231\u001b[39m     t: jnp.ndarray,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     train: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    236\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n\u001b[32m    237\u001b[39m     squeeze = x_t.ndim == \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     cond_mean, cond_logvar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcondition_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.condition_mode == \u001b[33m\"\u001b[39m\u001b[33mdeterministic\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    240\u001b[39m         cond_embedding = cond_mean\n",
      "    \u001b[31m[... skipping hidden 2 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/networks/_set_encoders.py:123\u001b[39m, in \u001b[36mConditionEncoder.__call__\u001b[39m\u001b[34m(self, conditions, training)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    106\u001b[39m     conditions: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, jnp.ndarray],\n\u001b[32m    107\u001b[39m     training: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    108\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[jnp.ndarray, jnp.ndarray]:\n\u001b[32m    109\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33;03m    Apply the set encoder.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m \u001b[33;03m    Mean and log-variance of conditions of shape ``(batch_size, output_dim)``.\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     mask, attention_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     \u001b[38;5;66;03m# apply modules before pooling\u001b[39;00m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.separate_inputs:\n",
      "    \u001b[31m[... skipping hidden 2 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/CellFlow2/src/scaleflow/networks/_set_encoders.py:230\u001b[39m, in \u001b[36mConditionEncoder._get_masks\u001b[39m\u001b[34m(self, conditions)\u001b[39m\n\u001b[32m    227\u001b[39m mask = jnp.expand_dims(mask, -\u001b[32m1\u001b[39m)\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# attention mask of shape (batch_size, 1, set_size, set_size)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m attention_mask = mask & \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m attention_mask = jnp.expand_dims(attention_mask, \u001b[32m1\u001b[39m)\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mask, attention_mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/scaleflow/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:1240\u001b[39m, in \u001b[36mmatrix_transpose\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1238\u001b[39m ndim = x.ndim\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ndim < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx must be at least two-dimensional for matrix_transpose; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1241\u001b[39m axes = (*\u001b[38;5;28mrange\u001b[39m(ndim - \u001b[32m2\u001b[39m), ndim - \u001b[32m1\u001b[39m, ndim - \u001b[32m2\u001b[39m)\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lax.transpose(x, axes)\n",
      "\u001b[31mValueError\u001b[39m: x must be at least two-dimensional for matrix_transpose; got ndim=1"
     ]
    }
   ],
   "source": [
    "sf.train(\n",
    "    val_dataloader=val_sampler,\n",
    "    train_dataloader=sampler,\n",
    "    num_iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84168581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaleflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
