{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Dataset Splitting with ScaleFlow\n",
    "\n",
    "This notebook demonstrates how to prepare and split multiple AnnData datasets using ScaleFlow's batch utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/scaleflow/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scaleflow.data import (\n",
    "    AnnDataLocation,\n",
    "    DataManager,\n",
    "    GroupedDistribution,\n",
    "    prepare_multiple_datasets,\n",
    "    split_multiple_datasets,\n",
    "    prepare_and_split_multiple_datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Sample Datasets\n",
    "\n",
    "First, let's create some synthetic AnnData objects that mimic perturbation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_adata(\n",
    "    n_obs: int = 1000,\n",
    "    n_vars: int = 50,\n",
    "    n_pca: int = 20,\n",
    "    n_drugs: int = 5,\n",
    "    n_genes: int = 3,\n",
    "    n_cell_lines: int = 3,\n",
    "    seed: int = 42,\n",
    ") -> ad.AnnData:\n",
    "    \"\"\"Create a synthetic AnnData for demonstration.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define categories\n",
    "    drugs = [\"control\"] + [f\"drug_{i}\" for i in range(n_drugs)]\n",
    "    genes = [\"control\"] + [f\"gene_{i}\" for i in range(n_genes)]\n",
    "    cell_lines = [f\"cell_line_{i}\" for i in range(n_cell_lines)]\n",
    "    \n",
    "    # Generate obs data\n",
    "    obs = pd.DataFrame({\n",
    "        \"drug\": np.random.choice(drugs, n_obs),\n",
    "        \"gene\": np.random.choice(genes, n_obs),\n",
    "        \"cell_line\": np.random.choice(cell_lines, n_obs),\n",
    "    })\n",
    "    \n",
    "    # Mark controls (both drug and gene are \"control\")\n",
    "    obs[\"control\"] = (obs[\"drug\"] == \"control\") & (obs[\"gene\"] == \"control\")\n",
    "    \n",
    "    # Convert to categorical\n",
    "    for col in [\"drug\", \"gene\", \"cell_line\"]:\n",
    "        obs[col] = obs[col].astype(\"category\")\n",
    "    \n",
    "    # Generate expression data\n",
    "    X = np.random.randn(n_obs, n_vars).astype(np.float32)\n",
    "    X_pca = np.random.randn(n_obs, n_pca).astype(np.float32)\n",
    "    \n",
    "    # Create AnnData\n",
    "    adata = ad.AnnData(X=X, obs=obs)\n",
    "    adata.obsm[\"X_pca\"] = X_pca\n",
    "    \n",
    "    # Create embeddings for conditions\n",
    "    adata.uns[\"cell_line_emb\"] = {\n",
    "        cl: np.random.randn(10).astype(np.float32) for cl in cell_lines\n",
    "    }\n",
    "    adata.uns[\"drug_emb\"] = {\n",
    "        d: np.random.randn(10).astype(np.float32) for d in drugs\n",
    "    }\n",
    "    adata.uns[\"gene_emb\"] = {\n",
    "        g: np.random.randn(10).astype(np.float32) for g in genes\n",
    "    }\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pbmc: 2000 cells, 50 genes\n",
      "  Drugs: 9, Genes: 5\n",
      "  Controls: 51\n",
      "\n",
      "zebrafish: 1500 cells, 50 genes\n",
      "  Drugs: 7, Genes: 4\n",
      "  Controls: 58\n",
      "\n",
      "ineuron: 1000 cells, 50 genes\n",
      "  Drugs: 6, Genes: 3\n",
      "  Controls: 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selman.ozleyen/mambaforge/envs/scaleflow/lib/python3.12/functools.py:912: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/Users/selman.ozleyen/mambaforge/envs/scaleflow/lib/python3.12/functools.py:912: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/Users/selman.ozleyen/mambaforge/envs/scaleflow/lib/python3.12/functools.py:912: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    }
   ],
   "source": [
    "# Create multiple synthetic datasets\n",
    "datasets = {\n",
    "    \"pbmc\": create_synthetic_adata(n_obs=2000, n_drugs=8, n_genes=4, seed=42),\n",
    "    \"zebrafish\": create_synthetic_adata(n_obs=1500, n_drugs=6, n_genes=3, seed=123),\n",
    "    \"ineuron\": create_synthetic_adata(n_obs=1000, n_drugs=5, n_genes=2, seed=456),\n",
    "}\n",
    "\n",
    "for name, adata in datasets.items():\n",
    "    print(f\"{name}: {adata.n_obs} cells, {adata.n_vars} genes\")\n",
    "    print(f\"  Drugs: {adata.obs['drug'].nunique()}, Genes: {adata.obs['gene'].nunique()}\")\n",
    "    print(f\"  Controls: {adata.obs['control'].sum()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure the DataManager\n",
    "\n",
    "Set up a single `DataManager` that will be used across all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataManager configured!\n"
     ]
    }
   ],
   "source": [
    "# Define the data location (where the cell features are stored)\n",
    "adl = AnnDataLocation()\n",
    "\n",
    "# Create a DataManager with shared configuration\n",
    "data_manager = DataManager(\n",
    "    dist_flag_key=\"control\",  # Boolean column marking control cells\n",
    "    src_dist_keys=[\"cell_line\"],  # Source distribution keys\n",
    "    tgt_dist_keys=[\"drug\", \"gene\"],  # Target distribution keys\n",
    "    rep_keys={\n",
    "        \"cell_line\": \"cell_line_emb\",\n",
    "        \"drug\": \"drug_emb\",\n",
    "        \"gene\": \"gene_emb\",\n",
    "    },\n",
    "    data_location=adl.obsm[\"X_pca\"],  # Use PCA embeddings\n",
    ")\n",
    "\n",
    "print(\"DataManager configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Multiple Datasets\n",
    "\n",
    "Use `prepare_multiple_datasets` to convert all AnnData objects to `GroupedDistribution` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting values...\n",
      "Sorting values took 0.00 seconds.\n",
      "Getting conditions...\n",
      "Getting conditions took 0.00 seconds.\n",
      "Getting source and target distribution data...\n",
      "Getting source and target distribution data took 0.00 seconds.\n",
      "Sorting values...\n",
      "Sorting values took 0.00 seconds.\n",
      "Getting conditions...\n",
      "Getting conditions took 0.00 seconds.\n",
      "Getting source and target distribution data...\n",
      "Getting source and target distribution data took 0.00 seconds.\n",
      "Sorting values...\n",
      "Sorting values took 0.00 seconds.\n",
      "Getting conditions...\n",
      "Getting conditions took 0.00 seconds.\n",
      "Getting source and target distribution data...\n",
      "Getting source and target distribution data took 0.00 seconds.\n",
      "\n",
      "pbmc:\n",
      "  Source distributions: 3\n",
      "  Target distributions: 132\n",
      "  Conditions: 132\n",
      "\n",
      "zebrafish:\n",
      "  Source distributions: 3\n",
      "  Target distributions: 81\n",
      "  Conditions: 81\n",
      "\n",
      "ineuron:\n",
      "  Source distributions: 3\n",
      "  Target distributions: 51\n",
      "  Conditions: 51\n"
     ]
    }
   ],
   "source": [
    "# Prepare all datasets at once\n",
    "grouped_distributions = prepare_multiple_datasets(\n",
    "    datasets=datasets,\n",
    "    data_manager=data_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "for name, gd in grouped_distributions.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Source distributions: {len(gd.data.src_data)}\")\n",
    "    print(f\"  Target distributions: {len(gd.data.tgt_data)}\")\n",
    "    print(f\"  Conditions: {len(gd.data.conditions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Multiple Datasets\n",
    "\n",
    "Use `split_multiple_datasets` to create train/val/test splits for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pbmc:\n",
      "  train: 3 source dists, 78 target dists\n",
      "  val: 3 source dists, 27 target dists\n",
      "  test: 3 source dists, 27 target dists\n",
      "\n",
      "zebrafish:\n",
      "  train: 3 source dists, 48 target dists\n",
      "  val: 3 source dists, 15 target dists\n",
      "  test: 3 source dists, 18 target dists\n",
      "\n",
      "ineuron:\n",
      "  train: 3 source dists, 30 target dists\n",
      "  val: 3 source dists, 9 target dists\n",
      "  test: 3 source dists, 12 target dists\n"
     ]
    }
   ],
   "source": [
    "# Split all datasets with the same configuration\n",
    "all_splits = split_multiple_datasets(\n",
    "    grouped_distributions=grouped_distributions,\n",
    "    holdout_combinations=False,\n",
    "    split_by=[\"drug\", \"gene\"],  # Split by drug-gene combinations\n",
    "    split_key=\"split\",\n",
    "    force_training_values={},  # No forced training values\n",
    "    ratios=[0.6, 0.2, 0.2],  # 60% train, 20% val, 20% test\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Examine the splits\n",
    "for dataset_name, splits in all_splits.items():\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    for split_name, gd in splits.items():\n",
    "        n_src = len(gd.data.src_data)\n",
    "        n_tgt = len(gd.data.tgt_data)\n",
    "        print(f\"  {split_name}: {n_src} source dists, {n_tgt} target dists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. One-Step: Prepare and Split Together\n",
    "\n",
    "Use `prepare_and_split_multiple_datasets` for a more convenient workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting values...\n",
      "Sorting values took 0.00 seconds.\n",
      "Getting conditions...\n",
      "Getting conditions took 0.00 seconds.\n",
      "Getting source and target distribution data...\n",
      "Getting source and target distribution data took 0.00 seconds.\n",
      "Sorting values...\n",
      "Sorting values took 0.00 seconds.\n",
      "Getting conditions...\n",
      "Getting conditions took 0.00 seconds.\n",
      "Getting source and target distribution data...\n",
      "Getting source and target distribution data took 0.00 seconds.\n",
      "Sorting values...\n",
      "Sorting values took 0.00 seconds.\n",
      "Getting conditions...\n",
      "Getting conditions took 0.00 seconds.\n",
      "Getting source and target distribution data...\n",
      "Getting source and target distribution data took 0.00 seconds.\n",
      "\n",
      "Datasets prepared and split:\n",
      "  - pbmc: train/val/test\n",
      "  - zebrafish: train/val/test\n",
      "  - ineuron: train/val/test\n"
     ]
    }
   ],
   "source": [
    "# Do everything in one step\n",
    "all_splits = prepare_and_split_multiple_datasets(\n",
    "    datasets=datasets, # dict like {\"dataset_name\": AnnData}\n",
    "    data_manager=data_manager,\n",
    "    holdout_combinations=False,\n",
    "    split_by=[\"drug\", \"gene\"],\n",
    "    ratios=[0.6, 0.2, 0.2],\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\nDatasets prepared and split:\")\n",
    "for dataset_name in all_splits:\n",
    "    print(f\"  - {dataset_name}: train/val/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Access Individual Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBMC Training Data:\n",
      "  Source distributions: 3\n",
      "  Target distributions: 78\n",
      "  Distribution DataFrame shape: (78, 5)\n",
      "\n",
      "Zebrafish Validation Data:\n",
      "  Source distributions: 3\n",
      "  Target distributions: 15\n"
     ]
    }
   ],
   "source": [
    "# Access a specific dataset and split\n",
    "pbmc_train = all_splits[\"pbmc\"][\"train\"]\n",
    "zebrafish_val = all_splits[\"zebrafish\"][\"val\"]\n",
    "\n",
    "print(\"PBMC Training Data:\")\n",
    "print(f\"  Source distributions: {len(pbmc_train.data.src_data)}\")\n",
    "print(f\"  Target distributions: {len(pbmc_train.data.tgt_data)}\")\n",
    "print(f\"  Distribution DataFrame shape: {pbmc_train.annotation.src_tgt_dist_df.shape}\")\n",
    "\n",
    "print(\"\\nZebrafish Validation Data:\")\n",
    "print(f\"  Source distributions: {len(zebrafish_val.data.src_data)}\")\n",
    "print(f\"  Target distributions: {len(zebrafish_val.data.tgt_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use with ReservoirSampler\n",
    "\n",
    "Create samplers for training on the split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pbmc sampler ready\n",
      "zebrafish sampler ready\n",
      "ineuron sampler ready\n"
     ]
    }
   ],
   "source": [
    "from scaleflow.data import ReservoirSampler\n",
    "\n",
    "# Create a sampler for each training dataset\n",
    "train_samplers = {}\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for dataset_name in all_splits:\n",
    "    train_data = all_splits[dataset_name][\"train\"]\n",
    "    sampler = ReservoirSampler(\n",
    "        data=train_data,\n",
    "        batch_size=128,\n",
    "    )\n",
    "    sampler.init_sampler(rng)\n",
    "    train_samplers[dataset_name] = sampler\n",
    "    print(f\"{dataset_name} sampler ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled source dist idx: 0 and target dist idx: 34\n",
      "sampled source batch: (128, 20)\n",
      "sampled target batch: (128, 20)\n",
      "\n",
      "pbmc batch:\n",
      "  Source cells: (128, 20)\n",
      "  Target cells: (128, 20)\n",
      "  Condition: (30,)\n",
      "sampled source dist idx: 0 and target dist idx: 13\n",
      "sampled source batch: (128, 20)\n",
      "sampled target batch: (128, 20)\n",
      "\n",
      "zebrafish batch:\n",
      "  Source cells: (128, 20)\n",
      "  Target cells: (128, 20)\n",
      "  Condition: (30,)\n",
      "sampled source dist idx: 2 and target dist idx: 34\n",
      "sampled source batch: (128, 20)\n",
      "sampled target batch: (128, 20)\n",
      "\n",
      "ineuron batch:\n",
      "  Source cells: (128, 20)\n",
      "  Target cells: (128, 20)\n",
      "  Condition: (30,)\n"
     ]
    }
   ],
   "source": [
    "# Sample from each dataset\n",
    "for dataset_name, sampler in train_samplers.items():\n",
    "    batch = sampler.sample(rng)\n",
    "    print(f\"\\n{dataset_name} batch:\")\n",
    "    print(f\"  Source cells: {batch['src_cell_data'].shape}\")\n",
    "    print(f\"  Target cells: {batch['tgt_cell_data'].shape}\")\n",
    "    print(f\"  Condition: {batch['condition'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset Split  Source Dists  Target Dists  Unique Drug-Gene Combos\n",
      "     pbmc train             3            78                       26\n",
      "     pbmc   val             3            27                        9\n",
      "     pbmc  test             3            27                        9\n",
      "zebrafish train             3            48                       16\n",
      "zebrafish   val             3            15                        5\n",
      "zebrafish  test             3            18                        6\n",
      "  ineuron train             3            30                       10\n",
      "  ineuron   val             3             9                        3\n",
      "  ineuron  test             3            12                        4\n"
     ]
    }
   ],
   "source": [
    "# Create a summary table\n",
    "summary_data = []\n",
    "\n",
    "for dataset_name, splits in all_splits.items():\n",
    "    for split_name, gd in splits.items():\n",
    "        summary_data.append({\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Split\": split_name,\n",
    "            \"Source Dists\": len(gd.data.src_data),\n",
    "            \"Target Dists\": len(gd.data.tgt_data),\n",
    "            \"Unique Drug-Gene Combos\": len(gd.annotation.src_tgt_dist_df.drop_duplicates(\n",
    "                subset=[\"drug\", \"gene\"]\n",
    "            )),\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Force Training Values Example\n",
    "\n",
    "Ensure specific drug or gene combinations always appear in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pbmc:\n",
      "  drug_0 in train: True\n",
      "  drug_0 in val: False\n",
      "  drug_0 in test: False\n",
      "\n",
      "zebrafish:\n",
      "  drug_0 in train: True\n",
      "  drug_0 in val: False\n",
      "  drug_0 in test: False\n",
      "\n",
      "ineuron:\n",
      "  drug_0 in train: True\n",
      "  drug_0 in val: False\n",
      "  drug_0 in test: False\n"
     ]
    }
   ],
   "source": [
    "# Force drug_0 to always be in training\n",
    "all_splits_forced = prepare_and_split_multiple_datasets(\n",
    "    datasets=datasets,\n",
    "    data_manager=data_manager,\n",
    "    holdout_combinations=False,\n",
    "    split_by=[\"drug\"],\n",
    "    force_training_values={\"drug\": \"drug_0\"},  # Ensure drug_0 is in training\n",
    "    ratios=[0.6, 0.2, 0.2],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Verify drug_0 is only in training\n",
    "for dataset_name, splits in all_splits_forced.items():\n",
    "    train_drugs = set(splits[\"train\"].annotation.src_tgt_dist_df[\"drug\"].unique())\n",
    "    val_drugs = set(splits[\"val\"].annotation.src_tgt_dist_df[\"drug\"].unique())\n",
    "    test_drugs = set(splits[\"test\"].annotation.src_tgt_dist_df[\"drug\"].unique())\n",
    "    \n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    print(f\"  drug_0 in train: {'drug_0' in train_drugs}\")\n",
    "    print(f\"  drug_0 in val: {'drug_0' in val_drugs}\")\n",
    "    print(f\"  drug_0 in test: {'drug_0' in test_drugs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaleflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
